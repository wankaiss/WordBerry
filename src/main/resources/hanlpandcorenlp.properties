# 这个配置文件包含coreNLP以及hanLP的所有配置参数
#本配置文件中的路径的根目录，根目录+其他路径=绝对路径
#Windows用户请注意，路径分隔符统一使用/
root=/Users/yanghui/Documents/
#核心词典路径
HanLPCoreDictionaryPath=data/dictionary/CoreNatureDictionary.txt
#2元语法词典路径
HanLPBiGramDictionaryPath=data/dictionary/CoreNatureDictionary.ngram.txt
#停用词词典路径
HanLPCoreStopWordDictionaryPath=data/dictionary/stopwords.txt
#同义词词典路径
HanLPCoreSynonymDictionaryDictionaryPath=data/dictionary/synonym/CoreSynonym.txt
#人名词典路径
HanLPPersonDictionaryPath=data/dictionary/person/nr.txt
#人名词典转移矩阵路径
HanLPPersonDictionaryTrPath=data/dictionary/person/nr.tr.txt
#繁简词典路径
HanLPTraditionalChineseDictionaryPath=data/dictionary/tc/TraditionalChinese.txt
#自定义词典路径，用;隔开多个自定义词典，空格开头表示在同一个目录，使用“文件名 词性”形式则表示这个词典的词性默认是该词性。优先级递减。
#另外data/dictionary/custom/CustomDictionary.txt是个高质量的词库，请不要删除
#CustomDictionaryPath=data/dictionary/custom/CustomDictionary.txt; 现代汉语补充词库.txt; 全国地名大全.txt ns; 人名词典.txt; 机构名词典.txt; 上海地名.txt ns;data/dictionary/person/nrf.txt nrf
#配置CRF分词模版
HanLPCRFSegmentModelPath=data/model/segment/CRFSegmentModel.txt.bin
#下面是coreNLP的model
#===========================================================
CoreNLPAnnotators=tokenize, ssplit, pos, lemma, ner, parse, dcoref
CoreNLPpkumodel=data/corenlpchinese/edu/stanford/nlp/models/segmenter/chinese/ctb.gz
CoreNLPctbmodel=data/corenlpchinese/edu/stanford/nlp/models/segmenter/chinese/ctb.gz;
CoreNLPsighanCorporaDict="edu/stanford/nlp/models/segmenter/chinese";
CoreNLPserDictionary="edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz"
CoreNLPsighanPostProcessing="true";
CoreNLPinputEncoding="UTF-8";
CoreNLPkeepAllWhitespaces="false";
# segment.model=data/corenlpchinese/edu/stanford/nlp/models/segmenter/chinese/ctb.gz
#segment.sighanCorporaDict=data/corenlpchinese/edu/stanford/nlp/models/segmenter/chinese
#segment.serDictionary=data/corenlpchinese/edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz
#pos.model=data/corenlpchinese/edu/stanford/nlp/models/pos-tagger/chinese-distsim/chinese-distsim.tagger
#ner.model=data/corenlpchinese/edu/stanford/nlp/models/ner/chinese.misc.distsim.crf.ser.gz
## regexner
#regexner.mapping=data/corenlpchinese/edu/stanford/nlp/models/kbp/cn_regexner_mapping.tab
## parse
#parse.model=data/corenlpchinese/edu/stanford/nlp/models/srparser/chineseSR.ser.gz
#depparse.model=data/corenlpchinese/edu/stanford/nlp/models/parser/nndep/UD_Chinese.gz
#coref.zh.dict=data/corenlpchinese/edu/stanford/nlp/models/dcoref/zh-attributes.txt.gz
## kbp
#kbp.semgrex=data/corenlpchinese/edu/stanford/nlp/models/kbp/chinese/semgrex
#kbp.tokensregex=data/corenlpchinese/edu/stanford/nlp/models/kbp/chinese/tokensregex
## entitylink
#entitylink.wikidict=data/corenlpchinese/edu/stanford/nlp/models/kbp/wikidict_chinese.tsv.gz

